{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NSRR HomePAP Features Extraction\n",
    "\n",
    "Note that we can only use in-lab recording because the at-home recording do not have the necessary channels.\n",
    "\n",
    "We also only use the \"full\" night and not the split-lab (during which the participants proceeded with CPAP titration).\n",
    "\n",
    "**WARNING:** \n",
    "\n",
    "1) C4 is C4-FPZ.\n",
    "\n",
    "https://sleepdata.org/datasets/homepap/pages/montage-and-sampling-rate-information.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os\n",
    "import yasa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from mne.io import read_raw_edf\n",
    "\n",
    "root_dir = '/Volumes/NSRR/homepap/'\n",
    "eeg_dir = root_dir + 'polysomnography/edfs/lab/full/'\n",
    "hypno_dir = root_dir + 'polysomnography/annotations-events-profusion/lab/full/'\n",
    "\n",
    "desc_dir = root_dir + 'datasets/homepap-baseline-dataset-0.1.0.csv'\n",
    "\n",
    "df_subj = pd.read_csv(desc_dir, usecols=['nsrrid', 'treatmentarm', 'age', 'gender', 'bmi', 'ahi_full',\n",
    "                                         'race3', 'ethnicity'])\n",
    "\n",
    "df_subj.rename(columns={\n",
    "    'nsrrid': 'subj',\n",
    "    'race3': 'race',\n",
    "    'ahi_full': 'ahi',\n",
    "    }, inplace=True)\n",
    "\n",
    "df_subj['race'].replace({1: 'caucasian', 2: 'african', 3: 'other'}, inplace=True)\n",
    "df_subj.loc[df_subj['ethnicity'] == 1, 'race'] = 'hispanic'\n",
    "df_subj.drop(columns=['ethnicity'], inplace=True)\n",
    "df_subj.rename(columns={'race': 'ethnicity'}, inplace=True)\n",
    "\n",
    "df_subj['male'] = df_subj['gender'].replace({'M': 1, 'F': 0})\n",
    "\n",
    "# Drop NaN\n",
    "df_subj.dropna(inplace=True)\n",
    "\n",
    "# Keep only in-lab PSG\n",
    "df_subj = df_subj[df_subj['treatmentarm'] == 'Lab']\n",
    "df_subj.drop(columns=['treatmentarm', 'gender'], inplace=True)\n",
    "\n",
    "# Keep only full night\n",
    "files = [int(f.split('-')[3]) for f in os.listdir(hypno_dir)]\n",
    "good = np.intersect1d(files, df_subj['subj'].values, assume_unique=True)\n",
    "df_subj = df_subj[df_subj['subj'].isin(good)]\n",
    "\n",
    "# Convert to str\n",
    "df_subj['subj'] = df_subj['subj'].astype(str)\n",
    "df_subj.set_index('subj', inplace=True)\n",
    "\n",
    "# Export demographics to CSV file\n",
    "df_subj['dataset'] = 'HOMEPAP'\n",
    "df_subj.to_csv(\"/Volumes/JAWA/SHERLOCK/demo/demo_nsrr_homepap.csv\")\n",
    "\n",
    "print(df_subj.shape[0], 'subjects remaining')\n",
    "df_subj.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "sf = 100\n",
    "\n",
    "for sub in tqdm(df_subj.index):\n",
    "    eeg_file = eeg_dir + 'homepap-lab-full-' + sub + '.edf'\n",
    "    hypno_file = hypno_dir + 'homepap-lab-full-' + sub + '-profusion.xml'\n",
    "\n",
    "    try:\n",
    "        raw = read_raw_edf(eeg_file, preload=False, verbose=0)\n",
    "        chan = raw.info['ch_names']\n",
    "        # Try different combinations of channels\n",
    "        # Do not delete! Channels have different names in HomePAP.\n",
    "        eeg_chan = np.intersect1d(chan, ['C4-M1', 'C4'])[0]\n",
    "        loc_chan = np.intersect1d(chan, ['E1', 'E-1', 'L-EOG'])[0]\n",
    "        emg_chan = np.intersect1d(chan, ['Lchin', 'LChin', 'Chin1-Chin2', 'EMG1', 'LCHIN'])[0]\n",
    "        include = [eeg_chan, loc_chan, emg_chan]\n",
    "        raw = read_raw_edf(\n",
    "            eeg_file, preload=True, exclude=np.setdiff1d(chan, include), verbose=0)\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "    # Resample and low-pass filter \n",
    "    raw.resample(sf, npad=\"auto\")\n",
    "    \n",
    "    # LOAD HYPNOGRAM\n",
    "    hypno, sf_hyp = yasa.load_profusion_hypno(hypno_file)\n",
    "    # We keep up to 15 minutes before / after sleep\n",
    "    start_to_firstsleep_min = np.nonzero(hypno)[0][0] / 2\n",
    "    lastsleep = np.nonzero(hypno)[0][-1]\n",
    "    lastsleep_to_end_min = (len(hypno) - lastsleep) / 2\n",
    "    tmin, tmax = 0, None  # must be in seconds\n",
    "    if start_to_firstsleep_min > 15:\n",
    "        tmin = (start_to_firstsleep_min - 15) * 60\n",
    "    if lastsleep_to_end_min > 15:\n",
    "        tmax = lastsleep * 30 + 15 * 60\n",
    "    # Crop!\n",
    "    raw.crop(tmin, tmax)\n",
    "    if tmax is None:\n",
    "        hypno = hypno[int(tmin / 60 * 2):]\n",
    "    else:\n",
    "        hypno = hypno[int(tmin / 60 * 2):int(tmax / 60 * 2)]\n",
    "    # Hypno and data have the same number of epochs\n",
    "    n_epochs = hypno.shape[0]\n",
    "    if n_epochs != np.floor(raw.n_times / sf / 30):\n",
    "        print(\"- Hypno and data size do not match.\")\n",
    "        continue\n",
    "    \n",
    "    # Convert hypnogram to str\n",
    "    df_hypno = pd.Series(hypno)\n",
    "    df_hypno.replace({0: 'W', 1: 'N1', 2: 'N2', 3: 'N3', 4: 'R'}, inplace=True)\n",
    "    stage_min = df_hypno.value_counts(sort=False) / 2\n",
    "\n",
    "    # INCLUSION CRITERIA\n",
    "    # Hypnogram must include all stages\n",
    "    if np.unique(hypno).tolist() != [0, 1, 2, 3, 4]:\n",
    "        print(\"- Not all stages are present.\")\n",
    "        continue\n",
    "    # If the duration is not between 4 to 12 hours, skip subject\n",
    "    if not(4 < n_epochs / 120 < 12):\n",
    "        print(\"- Recording too short/long.\")\n",
    "        continue\n",
    "    # Requires at least 5 min of each stage\n",
    "    # if (stage_min < 5).any():\n",
    "    #    print(\"- Not 5 min of each stage.\")\n",
    "    #    continue\n",
    "       \n",
    "    # EXTRACT FEATURES\n",
    "    metadata = dict(age=df_subj.loc[sub, 'age'], male=df_subj.loc[sub, 'male'])\n",
    "    sls = yasa.SleepStaging(raw, eeg_name=include[0], eog_name=include[1], \n",
    "                            emg_name=include[2], metadata=metadata)\n",
    "\n",
    "    features = sls.get_features().reset_index()\n",
    "    features['subj'] = sub\n",
    "    features.set_index(['subj', 'epoch'], inplace=True)\n",
    "    \n",
    "    # Add hypnogram\n",
    "    features['stage'] = df_hypno.to_numpy()\n",
    "    df.append(features)\n",
    "\n",
    "df = pd.concat(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add dataset\n",
    "df['dataset'] = 'homepap'\n",
    "\n",
    "# Convert to category\n",
    "df['dataset'] = df['dataset'].astype('category')\n",
    "df['stage'] = df['stage'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show %stage\n",
    "df['stage'].value_counts(normalize=True, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of unique nights in dataset\n",
    "df.index.get_level_values(0).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median value of the EEG IQR per stage\n",
    "df.groupby('stage')['eeg_iqr'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to Parquet\n",
    "df.to_parquet(\"/Volumes/JAWA/SHERLOCK/features/features_nsrr_homepap.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
