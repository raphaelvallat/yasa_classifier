{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NSRR HomePAP Features Extraction\n",
    "\n",
    "Note that we can only use in-lab recording because the at-home recording do not have the necessary channels.\n",
    "\n",
    "We also only use the \"full\" night and not the split-lab (during which the participants proceeded with CPAP titration).\n",
    "\n",
    "**WARNING:** \n",
    "\n",
    "1) C4 is C4-FPZ.\n",
    "\n",
    "https://sleepdata.org/datasets/homepap/pages/montage-and-sampling-rate-information.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os\n",
    "import yasa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from mne.io import read_raw_edf\n",
    "from preprocessing import crop_hypno, extract_features\n",
    "\n",
    "# Define paths\n",
    "root_dir = '/Volumes/NSRR/homepap/'\n",
    "eeg_dir = root_dir + 'polysomnography/edfs/lab/full/'\n",
    "hypno_dir = root_dir + 'polysomnography/annotations-events-profusion/lab/full/'\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "out_dir = parent_dir + '/output/features/'\n",
    "\n",
    "# Keep training set of HomePaP\n",
    "df_subj = pd.read_csv(parent_dir + \"/output/demo/demo_nsrr_all.csv\")\n",
    "df_subj = df_subj.query(\"dataset == 'HOMEPAP' and set == 'training'\").set_index(\"subj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "sf = 100\n",
    "\n",
    "for sub in tqdm(df_subj.index):\n",
    "    eeg_file = eeg_dir + 'homepap-lab-full-' + sub + '.edf'\n",
    "    hypno_file = hypno_dir + 'homepap-lab-full-' + sub + '-profusion.xml'\n",
    "\n",
    "    try:\n",
    "        raw = read_raw_edf(eeg_file, preload=False, verbose=0)\n",
    "        chan = raw.info['ch_names']\n",
    "        # Try different combinations of channels\n",
    "        # Do not delete! Channels have different names in HomePAP.\n",
    "        eeg_chan = np.intersect1d(chan, ['C4-M1', 'C4'])[0]\n",
    "        loc_chan = np.intersect1d(chan, ['E1', 'E-1', 'L-EOG'])[0]\n",
    "        emg_chan = np.intersect1d(chan, ['Lchin', 'LChin', 'Chin1-Chin2', 'EMG1', 'LCHIN'])[0]\n",
    "        include = [eeg_chan, loc_chan, emg_chan]\n",
    "        raw.drop_channels(np.setdiff1d(raw.info['ch_names'], include))\n",
    "        # Skip subjects if channel were not found\n",
    "        raw.load_data()\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "    # Resample and low-pass filter \n",
    "    raw.resample(sf, npad=\"auto\")\n",
    "    \n",
    "    # LOAD HYPNOGRAM\n",
    "    hypno, sf_hyp = yasa.load_profusion_hypno(hypno_file)\n",
    "    # We keep up to 15 minutes before / after sleep\n",
    "    hypno, tmin, tmax = crop_hypno(hypno)\n",
    "    # Crop EEG data\n",
    "    raw.crop(tmin, tmax)\n",
    "    \n",
    "    # Hypno and data have the same number of epochs\n",
    "    n_epochs = hypno.shape[0]\n",
    "    if n_epochs != np.floor(raw.n_times / sf / 30):\n",
    "        print(\"- Hypno and data size do not match.\")\n",
    "        continue\n",
    "    \n",
    "    # Convert hypnogram to str\n",
    "    df_hypno = pd.Series(hypno)\n",
    "    df_hypno.replace({0: 'W', 1: 'N1', 2: 'N2', 3: 'N3', 4: 'R'}, inplace=True)\n",
    "    stage_min = df_hypno.value_counts(sort=False) / 2\n",
    "\n",
    "    # INCLUSION CRITERIA\n",
    "    # Hypnogram must include all stages\n",
    "    if np.unique(hypno).tolist() != [0, 1, 2, 3, 4]:\n",
    "        print(\"- Not all stages are present.\")\n",
    "        continue\n",
    "    # If the duration is not between 4 to 12 hours, skip subject\n",
    "    if not(4 < n_epochs / 120 < 12):\n",
    "        print(\"- Recording too short/long.\")\n",
    "        continue\n",
    "       \n",
    "    # EXTRACT FEATURES\n",
    "    features = extract_features(df_subj, sub, raw, include)\n",
    "    # Add hypnogram\n",
    "    features['stage'] = df_hypno.to_numpy()\n",
    "    df.append(features)\n",
    "\n",
    "df = pd.concat(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add dataset\n",
    "df['dataset'] = 'homepap'\n",
    "\n",
    "# Convert to category\n",
    "df['dataset'] = df['dataset'].astype('category')\n",
    "df['stage'] = df['stage'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show %stage\n",
    "df['stage'].value_counts(normalize=True, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of unique nights in dataset\n",
    "df.index.get_level_values(0).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median value of the EEG IQR per stage\n",
    "df.groupby('stage')['eeg_iqr'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to Parquet\n",
    "df.to_parquet(out_dir + \"features_nsrr_homepap.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
