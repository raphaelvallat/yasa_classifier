{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NSRR CCSHS Features Extraction\n",
    "\n",
    "Unfortunately, for this dataset we do not have metric of signal quality and scoring reliability.\n",
    "\n",
    "**WARNING:** \n",
    "\n",
    "- All EEG, EOG and EMG are referenced to Fpz.\n",
    "- Sampling rate is 128 Hz with a highpass at 0.15 Hz.\n",
    "\n",
    "https://sleepdata.org/datasets/ccshs/pages/montage-and-sampling-rate-information.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yasa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from mne.io import read_raw_edf\n",
    "from preprocessing import crop_hypno, extract_features\n",
    "\n",
    "# Define paths\n",
    "root_dir = '/Volumes/NSRR/ccshs/'\n",
    "eeg_dir = root_dir + 'polysomnography/edfs/'\n",
    "hypno_dir = root_dir + 'polysomnography/annotations-events-profusion/'\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "out_dir = parent_dir + '/output/features/'\n",
    "\n",
    "# Keep training set of CCSHS only\n",
    "df_subj = pd.read_csv(parent_dir + \"/output/demo/demo_nsrr_all.csv\")\n",
    "df_subj = df_subj.query(\"dataset == 'CCSHS' and set == 'training'\").set_index(\"subj\")\n",
    "\n",
    "print(df_subj.shape[0], 'subjects remaining')\n",
    "df_subj.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "include = ['C4', 'LOC', 'EMG1']\n",
    "sf = 100\n",
    "\n",
    "for sub in tqdm(df_subj.index):\n",
    "    eeg_file = eeg_dir + 'ccshs-trec-' + sub + '.edf'\n",
    "    hypno_file = hypno_dir + 'ccshs-trec-' + sub + '-profusion.xml'\n",
    "\n",
    "    # LOAD EEG DATA\n",
    "    try:\n",
    "        # To deal with MNE loading error i_sub = 126\n",
    "        raw = read_raw_edf(eeg_file, preload=False, verbose=0)\n",
    "        raw = read_raw_edf(eeg_file, preload=True, \n",
    "                           exclude=np.setdiff1d(raw.info['ch_names'], include), \n",
    "                           verbose=0)\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "    # Resample and low-pass filter \n",
    "    raw.resample(sf, npad=\"auto\")\n",
    "    \n",
    "    # LOAD HYPNOGRAM\n",
    "    hypno, sf_hyp = yasa.load_profusion_hypno(hypno_file)\n",
    "    # We keep up to 15 minutes before / after sleep\n",
    "    hypno, tmin, tmax = crop_hypno(hypno)\n",
    "    # Crop EEG data\n",
    "    raw.crop(tmin, tmax)\n",
    "    # Check that hypno and data have the same number of epochs\n",
    "    n_epochs = hypno.shape[0]\n",
    "    if n_epochs != np.floor(raw.n_times / sf / 30):\n",
    "        print(\"- Hypno and data size do not match.\")\n",
    "        continue\n",
    "    \n",
    "    # Convert hypnogram to str\n",
    "    df_hypno = pd.Series(hypno)\n",
    "    df_hypno.replace({0: 'W', 1: 'N1', 2: 'N2', 3: 'N3', 4: 'R'}, inplace=True)\n",
    "    # stage_min = df_hypno.value_counts(sort=False) / 2\n",
    "\n",
    "    # INCLUSION CRITERIA\n",
    "    # Hypnogram must include all stages\n",
    "    if np.unique(hypno).tolist() != [0, 1, 2, 3, 4]:\n",
    "        print(\"- Not all stages are present.\")\n",
    "        continue\n",
    "    # Duration must be between 4 to 12 hours\n",
    "    if not(4 < n_epochs / 120 < 12):\n",
    "        print(\"- Recording too short/long.\")\n",
    "        continue\n",
    "\n",
    "    # EXTRACT FEATURES\n",
    "    features = extract_features(df_subj, sub, raw, include)\n",
    "    # Add hypnogram\n",
    "    features['stage'] = df_hypno.to_numpy()\n",
    "    df.append(features)\n",
    "\n",
    "df = pd.concat(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add dataset\n",
    "df['dataset'] = 'ccshs'\n",
    "\n",
    "# Convert to category\n",
    "df['dataset'] = df['dataset'].astype('category')\n",
    "df['stage'] = df['stage'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show %stage\n",
    "df['stage'].value_counts(normalize=True, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median value of the EEG IQR per stage\n",
    "df.groupby('stage')['eeg_iqr'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of unique nights in dataset\n",
    "df.index.get_level_values(0).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export feature file\n",
    "df.to_parquet(out_dir + \"features_nsrr_ccshs.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
