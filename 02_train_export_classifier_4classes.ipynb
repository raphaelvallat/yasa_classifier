{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit and export the sleep staging classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from lightgbm import LGBMClassifier\n",
    "sns.set(font_scale=1.25)\n",
    "\n",
    "# Define path\n",
    "parent_dir = os.getcwd()\n",
    "wdir = parent_dir + '/output/features/'\n",
    "wdir_demo = parent_dir + '/output/demo/'\n",
    "outdir = parent_dir + \"/output/classifiers/\"\n",
    "assert os.path.isdir(wdir)\n",
    "assert os.path.isdir(wdir_demo)\n",
    "assert os.path.isdir(outdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the feature files\n",
    "\n",
    "**Method 1: Loop across all datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# feat_files = glob.glob(wdir + \"features_nsrr*.parquet\")\n",
    "\n",
    "# df = []\n",
    "# for f in tqdm(feat_files):\n",
    "#     # Load current file\n",
    "#     print(f)\n",
    "#     tmp = pd.read_parquet(f)\n",
    "#     # Convert dtypes and downcast float\n",
    "#     tmp['age'] = tmp['age'].astype('int8')\n",
    "#     tmp['male'] = tmp['male'].astype('category')\n",
    "#     cols_float = tmp.select_dtypes(np.float64).columns.tolist()\n",
    "#     tmp[cols_float] = tmp[cols_float].astype(np.float32)\n",
    "#     # Append to main dataframe and delete tmp\n",
    "#     df.append(tmp)\n",
    "#     del tmp\n",
    "    \n",
    "# df = pd.concat(df)\n",
    "# print(\"There are %i unique nights\" % df.index.get_level_values(0).nunique())\n",
    "# df.head().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the concatenated file\n",
    "# df.to_parquet(wdir + \"features_all.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Method 2: Concatenated file**\n",
    "\n",
    "Need to run Method 1 at least once to enable this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Or we can simply use a pre-saved concatenated file\n",
    "df = pd.read_parquet(wdir + \"features_all.parquet\")\n",
    "\n",
    "# print(\"There are %i unique nights\" % df.index.get_level_values(0).nunique())\n",
    "# df.head().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check units of datasets\n",
    "df.groupby('dataset')['eeg_iqr'].describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add demographics (race, BMI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo = pd.read_csv(wdir_demo + \"demo_nsrr_all.csv\")\n",
    "# Remove columns that are already present in `df`\n",
    "df_demo.drop(columns=['male', 'age'], inplace=True)\n",
    "df_demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_subj = df.groupby(level=0, as_index=True)[['age', 'male', 'dataset']].first()\n",
    "grp_subj.reset_index(inplace=True)\n",
    "# Preprocessing before merge\n",
    "grp_subj['subj'] = grp_subj['subj'].astype(str)\n",
    "grp_subj['dataset'] = grp_subj['dataset'].str.upper()\n",
    "grp_subj['dataset'] = grp_subj['dataset'].replace({'SHHS1': 'SHHS'})\n",
    "# Left merge to keep only training set\n",
    "grp_subj = grp_subj.merge(df_demo, how=\"left\")\n",
    "grp_subj = grp_subj.sort_values(by=['dataset', 'subj']).reset_index(drop=True)\n",
    "grp_subj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptive statistics of the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values\n",
    "grp_subj.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of nights per dataset\n",
    "grp_subj['dataset'].value_counts(sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of hours / epochs\n",
    "df.shape[0] / 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_subj['male'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot age distribution\n",
    "def mean_std(x):\n",
    "    print(f\"{x.mean():.2f} Â± {x.std():.2f} (min = {x.min():.2f}, median = {x.median()}, max = {x.max():.2f})\")\n",
    "\n",
    "grp_subj['age'].agg(mean_std)\n",
    "grp_subj['age'].hist()\n",
    "plt.xlabel(\"Age\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_subj['ahi'].agg(mean_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_subj['bmi'].agg(mean_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100 * grp_subj['ethnicity'].value_counts(normalize=True).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create different combinations of predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_all = df.columns\n",
    "cols_time = cols_all[cols_all.str.startswith('time_')].tolist()\n",
    "# EEG also includes the time columns\n",
    "cols_eeg = cols_all[cols_all.str.startswith('eeg_')].tolist() + cols_time  \n",
    "cols_eog = cols_all[cols_all.str.startswith('eog_')].tolist()\n",
    "cols_emg = cols_all[cols_all.str.startswith('emg_')].tolist()\n",
    "cols_demo = ['age', 'male']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: 5 stages to 4 stages\n",
    "# If uncommenting, make sure to change the classifier file name!\n",
    "df['stage'].replace(\n",
    "    {'N1': 'LIGHT', 'N2': 'LIGHT', 'N3': 'DEEP', 'R': 'REM', 'W': 'WAKE'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define predictors\n",
    "X_all = {\n",
    "    'eeg': df[cols_eeg],\n",
    "    'eeg+demo': df[cols_eeg + cols_demo],\n",
    "    'eeg+eog': df[cols_eeg + cols_eog],\n",
    "    'eeg+eog+demo': df[cols_eeg + cols_eog + cols_demo],\n",
    "    'eeg+eog+emg': df[cols_eeg + cols_eog + cols_emg],\n",
    "    'eeg+eog+emg+demo': df[cols_eeg + cols_eog + cols_emg + cols_demo],\n",
    "}\n",
    "\n",
    "# Define target and groups\n",
    "y = df['stage']\n",
    "subjects = df.index.get_level_values(0).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export a full list of features\n",
    "features = pd.Series(X_all['eeg+eog+emg+demo'].columns, name=\"Features\")\n",
    "features.to_csv(\"features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % of each sleep stage\n",
    "y.value_counts(normalize=True).plot.barh(xlabel=\"Stage\", ylabel=\"Proportion\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyper-parameters\n",
    "params = dict(\n",
    "    boosting_type='gbdt',\n",
    "    n_estimators=300,\n",
    "    max_depth=7,\n",
    "    num_leaves=70,\n",
    "    colsample_bytree=0.8,\n",
    "    importance_type='gain',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.utils.class_weight import compute_class_weight\n",
    "# compute_class_weight('balanced', np.unique(y), y)\n",
    "\n",
    "# Manually define class weight\n",
    "# class_weight = None\n",
    "# class_weight = \"balanced\"\n",
    "class_weight = \"custom\"\n",
    "\n",
    "if class_weight == \"custom\":\n",
    "    # See output/classifiers/gridsearch_class_weights_4classes.csv\n",
    "    params['class_weight'] = {'LIGHT': 1, 'DEEP': 1.2, 'REM': 1.2, 'WAKE': 1}\n",
    "else:\n",
    "    params['class_weight'] = class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "\n",
    "## Fit the training set and export the trained classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parallel processing when building the trees.\n",
    "params['n_jobs'] = 12\n",
    "\n",
    "# Loop across combs of predictors\n",
    "for name, X in tqdm(X_all.items()):\n",
    "    \n",
    "    # Skip to full model\n",
    "    # if name != \"eeg+eog+emg+demo\":\n",
    "    #    continue\n",
    "    \n",
    "    # Fit\n",
    "    clf = LGBMClassifier(**params)\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    # Print the accuracy on the training dataset: shouldn't be too high..!\n",
    "    print(\"%s (%i features) - training accuracy: %.3f\" % \n",
    "        (name, X.shape[1], clf.score(X, y)))\n",
    "    \n",
    "    # Export trained classifier\n",
    "    if params['class_weight'] is not None:\n",
    "        fname = outdir + 'clf_%s_lgb_%s_%s_4classes.joblib' % \\\n",
    "        (name, params['boosting_type'], class_weight)\n",
    "    else:\n",
    "        fname = outdir + 'clf_%s_lgb_%s_4classes.joblib' % \\\n",
    "        (name, params['boosting_type'])\n",
    "        \n",
    "    # Export model\n",
    "    joblib.dump(clf, fname, compress=True)\n",
    "    \n",
    "    # Export LGBM feature importance\n",
    "    # df_imp = pd.Series(clf.feature_importances_, index=clf.feature_name_, name='Importance').round()\n",
    "    # df_imp.sort_values(ascending=False, inplace=True)\n",
    "    # df_imp.index.name = 'Features'\n",
    "    # df_imp.to_csv(fname[:-7] + \".csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
