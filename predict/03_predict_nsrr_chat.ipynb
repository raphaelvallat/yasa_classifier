{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NSRR CHAT Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yasa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from mne.io import read_raw_edf\n",
    "from preprocessing import crop_hypno\n",
    "\n",
    "DATASET = 'chat'\n",
    "\n",
    "# Define paths\n",
    "root_dir = '/Volumes/NSRR/%s/' % DATASET\n",
    "eeg_dir = root_dir + 'polysomnography/edfs/baseline/'\n",
    "hypno_dir = root_dir + 'polysomnography/annotations-events-profusion/baseline/'\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    "# Keep testing set\n",
    "df_subj = pd.read_csv(parent_dir + \"/output/demo/demo_nsrr_all.csv\")\n",
    "df_subj = df_subj.query(\"dataset == @DATASET.upper() and set == 'testing'\").set_index(\"subj\")\n",
    "\n",
    "print(df_subj.shape[0], 'subjects remaining')\n",
    "df_subj.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "include = ['C4', 'E1', 'Lchin']\n",
    "sf = 100\n",
    "models = [\"eeg\", \"eeg+eog\", \"eeg+eog+emg+demo\"]\n",
    "\n",
    "for sub in tqdm(df_subj.index):\n",
    "    eeg_file = eeg_dir + 'chat-baseline-' + str(sub) + '.edf'\n",
    "    hypno_file = hypno_dir + 'chat-baseline-' + str(sub) + '-profusion.xml'\n",
    "    \n",
    "    # Check that file exists\n",
    "    if not os.path.isfile(eeg_file):\n",
    "        warnings.warn(\"File not found %s\" % eeg_file)\n",
    "        continue\n",
    "    if not os.path.isfile(hypno_file):\n",
    "        warnings.warn(\"File not found %s\" % hypno_file)\n",
    "        continue\n",
    "\n",
    "    # LOAD EEG DATA\n",
    "    try:\n",
    "        raw = read_raw_edf(eeg_file, preload=False, verbose=0)\n",
    "        # Try different combinations of EMG channels\n",
    "        emg_chan = np.intersect1d(raw.ch_names, ['Lchin', 'LChin'])[0]\n",
    "        include = ['C4', 'E1', emg_chan]\n",
    "        raw.drop_channels(np.setdiff1d(raw.ch_names, include))\n",
    "        # Skip subjects if channel were not found\n",
    "        assert len(raw.ch_names) == len(include)\n",
    "        raw.load_data()\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "    # Resample and high-pass filter \n",
    "    raw.resample(sf, npad=\"auto\")\n",
    "    \n",
    "    # LOAD HYPNOGRAM\n",
    "    hypno, sf_hyp = yasa.load_profusion_hypno(hypno_file)\n",
    "    # Check that hypno and data have the same number of epochs\n",
    "    n_epochs = hypno.shape[0]\n",
    "    if n_epochs != np.floor(raw.n_times / sf / 30):\n",
    "        print(\"- Hypno and data size do not match.\")\n",
    "        continue\n",
    "    \n",
    "    # Convert hypnogram to str\n",
    "    df_hypno = pd.Series(hypno)\n",
    "    df_hypno.replace({0: 'W', 1: 'N1', 2: 'N2', 3: 'N3', 4: 'R'}, inplace=True)\n",
    "       \n",
    "    # PREDICT SLEEP STAGES\n",
    "    md = dict(age=df_subj.loc[sub, 'age'], male=df_subj.loc[sub, 'male'])\n",
    "    # Loop across classifiers\n",
    "    for model in models:\n",
    "        path_to_model = parent_dir + '/output/classifiers/clf_%s_lgb_gbdt_custom.joblib' % model\n",
    "        assert os.path.isfile(path_to_model)\n",
    "\n",
    "        if model == \"eeg\":\n",
    "            params = dict(eeg_name=include[0])\n",
    "        elif model == \"eeg+demo\":\n",
    "            params = dict(eeg_name=include[0], metadata=md)\n",
    "        elif model == \"eeg+eog\":\n",
    "            params = dict(eeg_name=include[0], eog_name=include[1])\n",
    "        elif model == \"eeg+eog+demo\":\n",
    "            params = dict(eeg_name=include[0], eog_name=include[1], metadata=md)\n",
    "        elif model == \"eeg+eog+emg\":\n",
    "            params = dict(eeg_name=include[0], eog_name=include[1], emg_name=include[2])\n",
    "        elif model == \"eeg+eog+emg+demo\":\n",
    "            params = dict(eeg_name=include[0], eog_name=include[1], emg_name=include[2], \n",
    "                          metadata=md)\n",
    "\n",
    "        # Predict stages and probability\n",
    "        sls = yasa.SleepStaging(raw, **params)\n",
    "        proba = sls.predict_proba(path_to_model)\n",
    "        confidence = proba.max(1).to_numpy()\n",
    "\n",
    "        # Append to temporary dataframe\n",
    "        df_pred = pd.DataFrame({\n",
    "            'subj': sub,\n",
    "            'model': model,\n",
    "            'age': md['age'],\n",
    "            'male': md['male'],\n",
    "            'y_true': df_hypno.to_numpy(),\n",
    "            'y_pred': sls.predict(path_to_model),\n",
    "            'confidence': confidence,\n",
    "            'proba_N1': proba.loc[:, 'N1'].to_numpy(),\n",
    "            'proba_N2': proba.loc[:, 'N2'].to_numpy(),\n",
    "            'proba_N3': proba.loc[:, 'N3'].to_numpy(),\n",
    "            'proba_R': proba.loc[:, 'R'].to_numpy(),\n",
    "            'proba_W': proba.loc[:, 'W'].to_numpy(),\n",
    "        })\n",
    "\n",
    "        df.append(df_pred)\n",
    "\n",
    "df = pd.concat(df)\n",
    "df['dataset'] = DATASET\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove subjects with an invalid stage\n",
    "bad_ss = df[~df['y_true'].isin(['W', 'N1', 'N2', 'N3', 'R'])]['subj'].to_numpy()\n",
    "df = df[~df['subj'].isin(bad_ss)]\n",
    "print(df['subj'].nunique(), 'subjects remaining')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to parquet, separately for each model\n",
    "for model in models:\n",
    "    out_dir = parent_dir + \"/output/cv/%s\" % model\n",
    "    if not os.path.isdir(out_dir): os.mkdir(out_dir)\n",
    "    df[df['model'] == model].to_parquet(out_dir + \"/cv_loo_nsrr_%s.parquet\" % DATASET, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
