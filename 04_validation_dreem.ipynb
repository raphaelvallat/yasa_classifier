{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dreem Open Datasets validation\n",
    "\n",
    "https://pubmed.ncbi.nlm.nih.gov/32746326/\n",
    "\n",
    "https://github.com/Dreem-Organization/dreem-learning-open\n",
    "\n",
    "https://github.com/Dreem-Organization/dreem-learning-evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pingouin as pg\n",
    "import sklearn.metrics as skm\n",
    "from tqdm.notebook import tqdm\n",
    "import scipy.stats as sp_stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from helper_functions import NUM2STR, STR2NUM\n",
    "from helper_functions import consensus_score, mean_std, median_iqr, perc_transition\n",
    "sns.set(style=\"ticks\", font_scale=1.1)\n",
    "\n",
    "outdir = \"output/plots/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load predictions file\n",
    "model = \"eeg+eog+emg+demo\"\n",
    "path_dodh = \"output/cv/%s/pred_dreem_dodh.csv\" % model\n",
    "path_dodo = \"output/cv/%s/pred_dreem_dodo.csv\" % model\n",
    "\n",
    "df = pd.concat([\n",
    "    pd.read_csv(path_dodh, index_col=[0, 1, 2]),\n",
    "    pd.read_csv(path_dodo, index_col=[0, 1, 2])\n",
    "])\n",
    "\n",
    "# Map stages\n",
    "labels = ['N1', 'N2', 'N3', 'R', 'W']\n",
    "cols_stage = df.columns.tolist()[:-3]\n",
    "print(cols_stage)\n",
    "\n",
    "for c in cols_stage:\n",
    "    df[c] = df[c].replace(NUM2STR)\n",
    "    assert np.unique(df[c]).tolist() == labels\n",
    "\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "# Optional: keep specific dataset\n",
    "# df = df[df['dataset'] == 'dodh'].reset_index(drop=True)\n",
    "\n",
    "print(df['subj'].nunique(), 'subjects')\n",
    "print(df.shape)\n",
    "df.head().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: remove subjects for which the hypnogram is shorter than the EEG by one minute or more\n",
    "df = df[df['pad'] <= 2].reset_index(drop=True)\n",
    "print(df['subj'].nunique(), 'subjects remaining')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: remove subjects with an average inter-rater agreement below 0.7\n",
    "# df = df[df['avg_human_agreement'] > 0.7].reset_index(drop=True)\n",
    "# print(df['subj'].nunique(), 'subjects remaining')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{df.shape[0] / 120:.2f} hours of data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "********\n",
    "\n",
    "## Calculate scores for each night"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_scorer = df.columns[df.columns.str.startswith(\"scorer\")].tolist()\n",
    "print(cols_scorer)\n",
    "\n",
    "df_scores = []\n",
    "\n",
    "# Loop across nights\n",
    "for sub in tqdm(df['subj'].unique(), leave=False):\n",
    "    df_sub = df[df['subj'] == sub]\n",
    "    \n",
    "    # Loop across scorers\n",
    "    for s in ['cons'] + ['yasa', 'stephansen', 'perslev'] + cols_scorer:\n",
    "        if s in cols_scorer:\n",
    "            # Consensus excluding current scorer (unbiased)\n",
    "            other_scorers = np.setdiff1d(cols_scorer, s).tolist()\n",
    "            yt = pd.Series(consensus_score(df_sub[other_scorers]), index=df_sub.index)\n",
    "        else:\n",
    "            yt = df_sub['cons']  # The reference is the human consensus\n",
    "\n",
    "        n = yt.shape[0]\n",
    "        yp = df_sub[s]\n",
    "\n",
    "        sub_scores = {\n",
    "            \"dataset\": df_sub['dataset'].iloc[0],\n",
    "            \"scorer\": s,\n",
    "            # Accuracy\n",
    "            'accuracy': 100 * skm.accuracy_score(yt, yp),\n",
    "            'kappa': 100 * skm.cohen_kappa_score(yt, yp),\n",
    "            'mcc': 100 * skm.matthews_corrcoef(yt, yp),\n",
    "            'f1_macro': 100 * skm.f1_score(yt, yp, average='macro', zero_division=1),\n",
    "            # % Transitions\n",
    "            # 'dur_min': yp.size / 2,\n",
    "            'perc_trans': perc_transition(yp),\n",
    "        }\n",
    "\n",
    "        # F1 for each stage\n",
    "        f1 = 100 * skm.f1_score(yt, yp, average=None, labels=labels, zero_division=1)\n",
    "        for f, l in zip(f1, labels):\n",
    "            sub_scores['f1_' + l] = f\n",
    "\n",
    "        # Proportion of each stage\n",
    "        prop = 100 * (yp.value_counts() / n).add_prefix('perc_')\n",
    "        sub_scores.update(prop.to_dict())\n",
    "\n",
    "        # Append to main dataframe\n",
    "        df_scores.append(pd.DataFrame(sub_scores, index=[sub]))\n",
    "\n",
    "df_scores = pd.concat(df_scores)\n",
    "df_scores.index.name = 'subj'\n",
    "df_scores = df_scores.sort_index(axis=1).set_index([\"dataset\", \"scorer\"], append=True)\n",
    "df_scores.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the NaN in perc_XX by zero: CAREFUL\n",
    "# df_scores.isna().sum(0)\n",
    "df_scores.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into DODH/DODO\n",
    "df_scores_dodh = df_scores.xs(\"dodh\", level=1)\n",
    "df_scores_dodo = df_scores.xs(\"dodo\", level=1)\n",
    "\n",
    "metrics = ['accuracy', 'f1_N1', 'f1_N2', 'f1_N3', 'f1_R', 'f1_W', 'f1_macro']\n",
    "scorers = ['yasa', 'stephansen', 'perslev'] + cols_scorer\n",
    "\n",
    "def median_iqr(x):\n",
    "    \"\"\"Return the median and IQR.\"\"\"\n",
    "    from scipy.stats import iqr\n",
    "    return f\"{x.median():.1f} Â± {iqr(x):.1f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores_dodh.groupby(level=-1, sort=False).agg(median_iqr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DODH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DODH only: Table 2\n",
    "dodh_table = df_scores_dodh.groupby(level=-1, sort=False).agg(median_iqr).T.loc[metrics, scorers]\n",
    "\n",
    "# Add significance\n",
    "for metric in metrics:\n",
    "    \n",
    "    # Calculate all pairwise tests yasa vs scorers\n",
    "    ptests = (df_scores_dodh\n",
    "              .reset_index()\n",
    "              .pairwise_ttests(dv=metric, within=\"scorer\", subject=\"subj\", return_desc=False)\n",
    "              [['A', 'B', 'T', 'dof', 'p-unc', 'hedges']]\n",
    "              .set_index(['A', 'B'])\n",
    "              .xs(\"yasa\", level=1, drop_level=False)\n",
    "              .drop(index=('cons', 'yasa'))\n",
    "              .droplevel(1))\n",
    "    \n",
    "    # Adjust for multiple comparisons\n",
    "    ptests['p-corr'] = pg.multicomp(ptests['p-unc'].to_numpy(), method=\"holm\")[1]\n",
    "    \n",
    "    # print(metric)\n",
    "    # display(ptests.round(3))\n",
    "\n",
    "    for scorer in cols_scorer + ['stephansen', 'perslev']:\n",
    "        pval = ptests.loc[scorer, 'p-corr']\n",
    "        hedges = ptests.loc[scorer, 'hedges']\n",
    "        if pval < 0.05:\n",
    "            dodh_table.loc[metric, scorer] += \"*\"\n",
    "            # dodh_table.loc[metric, scorer] += f\"* ({hedges:.2f})\"\n",
    "            \n",
    "dodh_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with io.StringIO() as buffer:\n",
    "    dodh_table.to_csv(buffer, sep=',', index=True)\n",
    "    print(buffer.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of unique nights\n",
    "df_scores_dodo.index.get_level_values(0).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DODO only: Table 3\n",
    "dodo_table = df_scores_dodo.groupby(level=-1, sort=False).agg(median_iqr).T.loc[metrics, scorers]\n",
    "\n",
    "# Add significance\n",
    "for metric in metrics:\n",
    "    \n",
    "    # Calculate all pairwise tests yasa vs scorers\n",
    "    ptests = (df_scores_dodo\n",
    "              .reset_index()\n",
    "              .pairwise_ttests(dv=metric, within=\"scorer\", subject=\"subj\", return_desc=True)\n",
    "              [['A', 'B', 'T', 'dof', 'p-unc', 'hedges']]\n",
    "              .set_index(['A', 'B'])\n",
    "              .xs(\"yasa\", level=1, drop_level=False)\n",
    "              .drop(index=('cons', 'yasa'))\n",
    "              .droplevel(1))\n",
    "    \n",
    "    # Adjust for multiple comparisons\n",
    "    ptests['p-corr'] = pg.multicomp(ptests['p-unc'].to_numpy(), method=\"holm\")[1]\n",
    "    \n",
    "    # print(metric)\n",
    "    # display(ptests.round(3))\n",
    "\n",
    "    for scorer in cols_scorer + ['stephansen', 'perslev']:\n",
    "        pval = ptests.loc[scorer, 'p-corr']\n",
    "        hedges = ptests.loc[scorer, 'hedges']\n",
    "        if pval < 0.05:\n",
    "            dodo_table.loc[metric, scorer] += \"*\"\n",
    "            # dodo_table.loc[metric, scorer] += f\"* ({hedges:.2f})\"\n",
    "            \n",
    "dodo_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with io.StringIO() as buffer:\n",
    "    dodo_table.to_csv(buffer, sep=',', index=True)\n",
    "    print(buffer.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = list(sns.color_palette(\"Blues\", n_colors=10, as_cmap=False, desat=1))\n",
    "color_pred = cmap[-1]\n",
    "color_ref = \"tab:orange\"\n",
    "cmap_stages = ['#99d7f1', '#009DDC', 'xkcd:twilight blue', 'xkcd:rich purple', 'xkcd:sunflower']\n",
    "\n",
    "df_f1 = df_scores[['f1_N1', 'f1_N2', 'f1_N3', 'f1_R', 'f1_W']].copy()\n",
    "df_f1.columns = df_f1.columns.str.split('_').str.get(1)\n",
    "\n",
    "df_f1_dodh = df_f1.xs(\"dodh\", level=1)\n",
    "df_f1_dodo = df_f1.xs(\"dodo\", level=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DODH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(10, 4), sharex=True, sharey=True)\n",
    "\n",
    "sns.boxplot(data=df_f1_dodh.xs(\"yasa\", level=-1), palette=cmap_stages, width=0.6, fliersize=0, ax=ax1)\n",
    "sns.boxplot(data=df_f1_dodh.xs(\"stephansen\", level=-1), palette=cmap_stages, width=0.6, fliersize=0, ax=ax2)\n",
    "sns.boxplot(data=df_f1_dodh.xs(\"perslev\", level=-1), palette=cmap_stages, width=0.6, fliersize=0, ax=ax3)\n",
    "\n",
    "ax1.set_title(\"YASA\")\n",
    "ax2.set_title(\"Stephansen 2018\")\n",
    "ax3.set_title(\"Perslev 2021\")\n",
    "\n",
    "ax1.set_xlabel(\"Stage\")\n",
    "ax2.set_xlabel(\"Stage\")\n",
    "ax3.set_xlabel(\"Stage\")\n",
    "ax1.set_ylabel(\"F1-score\")\n",
    "ax1.set_ylim(0, 103)\n",
    "sns.despine()\n",
    "\n",
    "plt.savefig(outdir + \"cv_F1_DODH_algorithms.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(10, 4), sharex=True, sharey=True)\n",
    "\n",
    "sns.boxplot(data=df_f1_dodo.xs(\"yasa\", level=-1), palette=cmap_stages, width=0.6, fliersize=0, ax=ax1)\n",
    "sns.boxplot(data=df_f1_dodo.xs(\"stephansen\", level=-1), palette=cmap_stages, width=0.6, fliersize=0, ax=ax2)\n",
    "sns.boxplot(data=df_f1_dodo.xs(\"perslev\", level=-1), palette=cmap_stages, width=0.6, fliersize=0, ax=ax3)\n",
    "\n",
    "ax1.set_title(\"YASA\")\n",
    "ax2.set_title(\"Stephansen 2018\")\n",
    "ax3.set_title(\"Perslev 2021\")\n",
    "\n",
    "ax1.set_xlabel(\"Stage\")\n",
    "ax2.set_xlabel(\"Stage\")\n",
    "ax3.set_xlabel(\"Stage\")\n",
    "ax1.set_ylabel(\"F1-score\")\n",
    "ax1.set_ylim(0, 103)\n",
    "sns.despine()\n",
    "\n",
    "plt.savefig(outdir + \"cv_F1_DODO_algorithms.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****\n",
    "\n",
    "## Confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dodo = df[df['dataset'] == \"dodo\"]\n",
    "df_dodh = df[df['dataset'] == \"dodh\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate sensitivity confusion matrices\n",
    "cm_yasa = 100 * skm.confusion_matrix(df_dodo['cons'], df_dodo['yasa'], labels=labels, normalize=\"true\")\n",
    "cm_yasa = pd.DataFrame(cm_yasa, index=labels, columns=labels).round(1)\n",
    "\n",
    "cm_stephansen = 100 * skm.confusion_matrix(df_dodo['cons'], df_dodo['stephansen'], labels=labels, normalize=\"true\")\n",
    "cm_stephansen = pd.DataFrame(cm_stephansen, index=labels, columns=labels).round(1)\n",
    "\n",
    "cm_perslev = 100 * skm.confusion_matrix(df_dodo['cons'], df_dodo['perslev'], labels=labels, normalize=\"true\")\n",
    "cm_perslev = pd.DataFrame(cm_perslev, index=labels, columns=labels).round(1)\n",
    "\n",
    "# Plot\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(10, 4), sharey=True)\n",
    "\n",
    "hmap_params = dict(annot=True, vmin=0, vmax=100, cmap=\"Blues\", square=True, cbar=False, fmt=\".1f\")\n",
    "sns.heatmap(cm_yasa, **hmap_params, ax=ax1)\n",
    "sns.heatmap(cm_stephansen, **hmap_params, ax=ax2)\n",
    "sns.heatmap(cm_perslev, **hmap_params, ax=ax3)\n",
    "\n",
    "ax1.set_ylabel(\"Reference (human consensus)\")\n",
    "ax1.set_xlabel(\"Predicted\")\n",
    "ax2.set_xlabel(\"Predicted\")\n",
    "ax3.set_xlabel(\"Predicted\")\n",
    "\n",
    "ax1.set_title(\"YASA\")\n",
    "ax2.set_title(\"Stephansen 2018\")\n",
    "ax3.set_title(\"Perslev 2021\")\n",
    "\n",
    "plt.savefig(outdir + \"cv_confusion_DODO_algorithms.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Individual human scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate sensitivity confusion matrices\n",
    "cm_h1 = 100 * skm.confusion_matrix(df_dodo['cons'], df_dodo['scorer_1'], labels=labels, normalize=\"true\")\n",
    "cm_h1 = pd.DataFrame(cm_h1, index=labels, columns=labels).round(1)\n",
    "\n",
    "cm_h2 = 100 * skm.confusion_matrix(df_dodo['cons'], df_dodo['scorer_2'], labels=labels, normalize=\"true\")\n",
    "cm_h2 = pd.DataFrame(cm_h2, index=labels, columns=labels).round(1)\n",
    "\n",
    "cm_h3 = 100 * skm.confusion_matrix(df_dodo['cons'], df_dodo['scorer_3'], labels=labels, normalize=\"true\")\n",
    "cm_h3 = pd.DataFrame(cm_h3, index=labels, columns=labels).round(1)\n",
    "\n",
    "cm_h4 = 100 * skm.confusion_matrix(df_dodo['cons'], df_dodo['scorer_4'], labels=labels, normalize=\"true\")\n",
    "cm_h4 = pd.DataFrame(cm_h4, index=labels, columns=labels).round(1)\n",
    "\n",
    "cm_h5 = 100 * skm.confusion_matrix(df_dodo['cons'], df_dodo['scorer_5'], labels=labels, normalize=\"true\")\n",
    "cm_h5 = pd.DataFrame(cm_h5, index=labels, columns=labels).round(1)\n",
    "\n",
    "\n",
    "# Plot\n",
    "fig, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(2, 3, figsize=(10, 8), sharey=True)\n",
    "\n",
    "hmap_params = dict(annot=True, vmin=0, vmax=100, cmap=\"Blues\", square=True, cbar=False, fmt=\".1f\")\n",
    "sns.heatmap(cm_h1, **hmap_params, ax=ax1)\n",
    "sns.heatmap(cm_h2, **hmap_params, ax=ax2)\n",
    "sns.heatmap(cm_h3, **hmap_params, ax=ax3)\n",
    "sns.heatmap(cm_h4, **hmap_params, ax=ax4)\n",
    "sns.heatmap(cm_h5, **hmap_params, ax=ax5)\n",
    "\n",
    "ax1.set_ylabel(\"N-1 consensus\")\n",
    "ax4.set_ylabel(\"N-1 consensus\")\n",
    "ax1.set_xlabel(\"Predicted\")\n",
    "ax2.set_xlabel(\"Predicted\")\n",
    "ax3.set_xlabel(\"Predicted\")\n",
    "ax4.set_xlabel(\"Predicted\")\n",
    "ax5.set_xlabel(\"Predicted\")\n",
    "\n",
    "ax1.set_title(\"H1\")\n",
    "ax2.set_title(\"H2\")\n",
    "ax3.set_title(\"H3\")\n",
    "ax4.set_title(\"H4\")\n",
    "ax5.set_title(\"H5\")\n",
    "\n",
    "ax6.axis('off');\n",
    "\n",
    "plt.savefig(outdir + \"cv_confusion_DODO_humans.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DODH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate sensitivity confusion matrices\n",
    "cm_yasa = 100 * skm.confusion_matrix(df_dodh['cons'], df_dodh['yasa'], labels=labels, normalize=\"true\")\n",
    "cm_yasa = pd.DataFrame(cm_yasa, index=labels, columns=labels).round(1)\n",
    "\n",
    "cm_stephansen = 100 * skm.confusion_matrix(df_dodh['cons'], df_dodh['stephansen'], labels=labels, normalize=\"true\")\n",
    "cm_stephansen = pd.DataFrame(cm_stephansen, index=labels, columns=labels).round(1)\n",
    "\n",
    "cm_perslev = 100 * skm.confusion_matrix(df_dodh['cons'], df_dodh['perslev'], labels=labels, normalize=\"true\")\n",
    "cm_perslev = pd.DataFrame(cm_perslev, index=labels, columns=labels).round(1)\n",
    "\n",
    "# Plot\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(10, 4), sharey=True)\n",
    "\n",
    "hmap_params = dict(annot=True, vmin=0, vmax=100, cmap=\"Blues\", square=True, cbar=False, fmt=\".1f\")\n",
    "sns.heatmap(cm_yasa, **hmap_params, ax=ax1)\n",
    "sns.heatmap(cm_stephansen, **hmap_params, ax=ax2)\n",
    "sns.heatmap(cm_perslev, **hmap_params, ax=ax3)\n",
    "\n",
    "\n",
    "ax1.set_ylabel(\"Reference (human consensus)\")\n",
    "ax1.set_xlabel(\"Predicted\")\n",
    "ax2.set_xlabel(\"Predicted\")\n",
    "ax3.set_xlabel(\"Predicted\")\n",
    "\n",
    "ax1.set_title(\"YASA\")\n",
    "ax2.set_title(\"Stephansen 2018\")\n",
    "ax3.set_title(\"Perslev 2021\")\n",
    "\n",
    "plt.savefig(outdir + \"cv_confusion_DODH_algorithms.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Individual human scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate sensitivity confusion matrices\n",
    "cm_h1 = 100 * skm.confusion_matrix(df_dodh['cons'], df_dodh['scorer_1'], labels=labels, normalize=\"true\")\n",
    "cm_h1 = pd.DataFrame(cm_h1, index=labels, columns=labels).round(1)\n",
    "\n",
    "cm_h2 = 100 * skm.confusion_matrix(df_dodh['cons'], df_dodh['scorer_2'], labels=labels, normalize=\"true\")\n",
    "cm_h2 = pd.DataFrame(cm_h2, index=labels, columns=labels).round(1)\n",
    "\n",
    "cm_h3 = 100 * skm.confusion_matrix(df_dodh['cons'], df_dodh['scorer_3'], labels=labels, normalize=\"true\")\n",
    "cm_h3 = pd.DataFrame(cm_h3, index=labels, columns=labels).round(1)\n",
    "\n",
    "cm_h4 = 100 * skm.confusion_matrix(df_dodh['cons'], df_dodh['scorer_4'], labels=labels, normalize=\"true\")\n",
    "cm_h4 = pd.DataFrame(cm_h4, index=labels, columns=labels).round(1)\n",
    "\n",
    "cm_h5 = 100 * skm.confusion_matrix(df_dodh['cons'], df_dodh['scorer_5'], labels=labels, normalize=\"true\")\n",
    "cm_h5 = pd.DataFrame(cm_h5, index=labels, columns=labels).round(1)\n",
    "\n",
    "\n",
    "# Plot\n",
    "fig, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(2, 3, figsize=(10, 8), sharey=True)\n",
    "\n",
    "hmap_params = dict(annot=True, vmin=0, vmax=100, cmap=\"Blues\", square=True, cbar=False, fmt=\".1f\")\n",
    "sns.heatmap(cm_h1, **hmap_params, ax=ax1)\n",
    "sns.heatmap(cm_h2, **hmap_params, ax=ax2)\n",
    "sns.heatmap(cm_h3, **hmap_params, ax=ax3)\n",
    "sns.heatmap(cm_h4, **hmap_params, ax=ax4)\n",
    "sns.heatmap(cm_h5, **hmap_params, ax=ax5)\n",
    "\n",
    "ax1.set_ylabel(\"N-1 consensus\")\n",
    "ax4.set_ylabel(\"N-1 consensus\")\n",
    "ax1.set_xlabel(\"Predicted\")\n",
    "ax2.set_xlabel(\"Predicted\")\n",
    "ax3.set_xlabel(\"Predicted\")\n",
    "ax4.set_xlabel(\"Predicted\")\n",
    "ax5.set_xlabel(\"Predicted\")\n",
    "\n",
    "ax1.set_title(\"H1\")\n",
    "ax2.set_title(\"H2\")\n",
    "ax3.set_title(\"H3\")\n",
    "ax4.set_title(\"H4\")\n",
    "ax5.set_title(\"H5\")\n",
    "\n",
    "ax6.axis('off');\n",
    "\n",
    "plt.savefig(outdir + \"cv_confusion_DODH_humans.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "********\n",
    "\n",
    "## Stage discrepancies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentage of transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DODO\n",
    "pg.ttest(\n",
    "    df_scores_dodo.xs(\"cons\", level=-1)['perc_trans'], \n",
    "    df_scores_dodo.xs(\"yasa\", level=-1)['perc_trans'], \n",
    "    paired=True).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DODH\n",
    "pg.ttest(\n",
    "    df_scores_dodh.xs(\"cons\", level=-1)['perc_trans'], \n",
    "    df_scores_dodh.xs(\"yasa\", level=-1)['perc_trans'], \n",
    "    paired=True).round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_perc = ['perc_' + c for c in labels]\n",
    "df_prop = df_scores[cols_perc].melt(var_name=\"stage\", value_name=\"proportion\", ignore_index=False).reset_index()\n",
    "df_prop = df_prop[df_prop['scorer'].isin(['cons', 'yasa'])]\n",
    "df_prop['scorer'].replace({\"cons\": \"Consensus\", \"yasa\": \"YASA\"}, inplace=True)\n",
    "df_prop['stage'] = df_prop['stage'].str.split(\"_\").str.get(1)\n",
    "df_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the effect size\n",
    "ptest = df_prop.pairwise_ttests(dv=\"proportion\", within=['stage', \"scorer\"], subject=\"subj\", effsize=\"cohen\").iloc[11:, :].round(3)\n",
    "ef = ptest.loc[:, ['stage', 'cohen']].set_index(\"stage\").abs()\n",
    "display(ef)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4, 4))\n",
    "\n",
    "sns.boxplot(\n",
    "    y=df_prop['proportion'], x=df_prop['stage'], hue=df_prop['scorer'],\n",
    "    hue_order=['Consensus', 'YASA'], \n",
    "    palette=[color_ref, color_pred], \n",
    "    saturation=1, width=0.6, fliersize=0, linewidth=1.5, notch=True);\n",
    "\n",
    "plt.ylim(0, 80)\n",
    "plt.yticks([0, 20, 40, 60, 80])\n",
    "plt.legend(frameon=False, loc=\"upper right\")\n",
    "plt.ylabel(\"Proportion of time in bed (%)\");\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*******\n",
    "\n",
    "## Additional analyses \n",
    "\n",
    "### Stage transition and confidence\n",
    "\n",
    "Here, we use PSG consensus-hypnogram to define the transitions between stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans = []\n",
    "\n",
    "for sub in tqdm(df['subj'].unique(), leave=False):\n",
    "    df_sub = df[df['subj'] == sub]\n",
    "    dataset = df_sub['dataset'].iloc[0]\n",
    "    yt = df_sub['cons']\n",
    "    yp = df_sub['yasa']\n",
    "    n = yt.size\n",
    "\n",
    "    # Identify stable periods, i.e. the 3 epochs before / after are similar (3 minutes window)\n",
    "    first_ep, last_ep = yt.iloc[0], yt.iloc[-1]\n",
    "    stable = np.logical_and.reduce((\n",
    "        yt.shift(1, fill_value=first_ep) == yt,  # = same as previous one\n",
    "        yt.shift(-1, fill_value=last_ep) == yt, # = same as next one\n",
    "        yt.shift(2, fill_value=first_ep) == yt,\n",
    "        yt.shift(-2, fill_value=last_ep) == yt,\n",
    "        yt.shift(3, fill_value=first_ep) == yt,\n",
    "        yt.shift(-3, fill_value=last_ep) == yt,\n",
    "    ))\n",
    "    \n",
    "    # Does low human inter-rater agreement occur mostly around stage transitions?\n",
    "    consensus = (df_sub[cols_scorer].nunique(1) == 1).to_numpy()\n",
    "    \n",
    "    # Confidence of the algorithm\n",
    "    highconf = (df_sub['confidence'] >= 0.8).to_numpy()\n",
    "    \n",
    "    # Append to main dict\n",
    "    sub_scores = {\n",
    "        # Stage transition\n",
    "        'p_stable': len(stable[stable]) / n,\n",
    "        'p_trans': len(stable[~stable]) / n,\n",
    "        'p_consensus': consensus.sum() / n,\n",
    "        'p_nocons': np.sum(~consensus) / n,\n",
    "        \n",
    "        'p_stable_and_consensus':(stable & consensus).sum() / n,\n",
    "        'p_stable_and_nocons': (stable & ~consensus).sum() / n,\n",
    "        'p_trans_and_consensus': (~stable & consensus).sum() / n,\n",
    "        'p_trans_and_nocons': (~stable & ~consensus).sum() / n,\n",
    "        'acc_stable': skm.accuracy_score(yt[stable], yp[stable]),\n",
    "        'acc_trans': skm.accuracy_score(yt[~stable], yp[~stable]),\n",
    "        \n",
    "        # Confidence\n",
    "        'accuracy': skm.accuracy_score(yt, yp),\n",
    "        'avg_confidence': df_sub['confidence'].mean(),\n",
    "        'p_highconf': len(highconf[highconf]) / n,\n",
    "        'p_lowconf': len(highconf[~highconf]) / n,\n",
    "        'p_highconf_and_consensus':(highconf & consensus).sum() / n,\n",
    "        'p_highconf_and_nocons': (highconf & ~consensus).sum() / n,\n",
    "        'p_lowconf_and_consensus': (~highconf & consensus).sum() / n,\n",
    "        'p_lowconf_and_nocons': (~highconf & ~consensus).sum() / n,\n",
    "        'acc_highconf': skm.accuracy_score(yt[highconf], yp[highconf]),\n",
    "        'acc_lowconf': skm.accuracy_score(yt[~highconf], yp[~highconf]),\n",
    "    }\n",
    "\n",
    "    # Append to main dataframe\n",
    "    tmp = 100 * pd.DataFrame(sub_scores, index=[sub])\n",
    "    tmp.index.name = \"subj\"\n",
    "    tmp['dataset'] = dataset\n",
    "    tmp.set_index(\"dataset\", append=True, inplace=True)\n",
    "    df_trans.append(tmp)\n",
    "\n",
    "df_trans = pd.concat(df_trans)\n",
    "df_trans.sort_index(axis=1, inplace=True)\n",
    "df_trans.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy x Stage transition\n",
    "display(df_trans[['acc_stable', 'acc_trans']].apply(mean_std))\n",
    "pg.ttest(df_trans['acc_stable'], df_trans['acc_trans'], paired=False).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy x Confidence\n",
    "display(df_trans[['acc_highconf', 'acc_lowconf']].apply(mean_std))\n",
    "pg.ttest(df_trans['acc_highconf'], df_trans['acc_lowconf'], paired=False).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage transition x unanimous consensus\n",
    "display(df_trans[['p_stable_and_consensus', 'p_trans_and_consensus']].apply(mean_std))\n",
    "pg.ttest(df_trans['p_stable_and_consensus'], df_trans['p_trans_and_consensus'], paired=False).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confidence x unanimous consensus\n",
    "display(df_trans[['p_highconf_and_consensus', 'p_lowconf_and_consensus']].apply(mean_std))\n",
    "pg.ttest(df_trans['p_highconf_and_consensus'], df_trans['p_lowconf_and_consensus'], paired=False).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation % high confidence epochs vs % unanimous consensus epochs\n",
    "pg.corr(df_trans['p_highconf'], df_trans['p_consensus']).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average YASA confidence in sleep apnea vs healthy individuals\n",
    "display(df_trans.groupby('dataset')['avg_confidence'].apply(mean_std))\n",
    "df_trans.reset_index().pairwise_ttests(dv=\"avg_confidence\", between=\"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percent high confidence in sleep apnea vs healthy individuals\n",
    "display(df_trans.groupby('dataset')['p_highconf'].apply(mean_std))\n",
    "df_trans.reset_index().pairwise_ttests(dv=\"p_highconf\", between=\"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percent unanimous consensus in sleep apnea vs healthy individuals\n",
    "display(df_trans.groupby('dataset')['p_consensus'].apply(mean_std))\n",
    "df_trans.reset_index().pairwise_ttests(dv=\"p_consensus\", between=\"dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidence x Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_conf = df_trans.xs(\"dodh\", level=-1).pairwise_corr(['avg_confidence', 'accuracy']).round(3)\n",
    "display(corr_conf)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(3.5, 3.5), dpi=100)\n",
    "sns.regplot(data=df_trans.xs(\"dodh\", level=-1), x=\"avg_confidence\", y=\"accuracy\", truncate=True, order=1,\n",
    "            scatter_kws={\"s\": 20, \"alpha\": .2, \"lw\": 1},\n",
    "            line_kws={\"color\": \"k\", \"lw\": 3}, \n",
    "            color=color_pred, ax=ax)\n",
    "plt.xlim(60, 100)\n",
    "plt.ylim(50, 100)\n",
    "plt.xlabel(\"Average confidence\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "\n",
    "plt.annotate(\"r=%.2f\" % corr_conf.loc[0, 'r'], (0.6, 0.1), xycoords=\"axes fraction\", fontstyle=\"italic\")\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.savefig(outdir + \"cv_accuracy_confidence_DODH.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_conf = df_trans.xs(\"dodo\", level=-1).pairwise_corr(['avg_confidence', 'accuracy']).round(3)\n",
    "display(corr_conf)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(3.5, 3.5), dpi=100)\n",
    "sns.regplot(data=df_trans.xs(\"dodo\", level=-1), x=\"avg_confidence\", y=\"accuracy\", truncate=True, order=1,\n",
    "            scatter_kws={\"s\": 20, \"alpha\": .2, \"lw\": 1},\n",
    "            line_kws={\"color\": \"k\", \"lw\": 3}, \n",
    "            color=color_pred, ax=ax)\n",
    "plt.xlim(60, 100)\n",
    "plt.ylim(50, 100)\n",
    "plt.xlabel(\"Average confidence\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "\n",
    "plt.annotate(\"r=%.2f\" % corr_conf.loc[0, 'r'], (0.6, 0.1), xycoords=\"axes fraction\", fontstyle=\"italic\")\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.savefig(outdir + \"cv_accuracy_confidence_DODO.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Plot hypnogram\n",
    "\n",
    "Ranked by YASA accuracy (from highest to lowest accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# Change Seaborn style\n",
    "sns.set(style=\"darkgrid\", font_scale=1.2)\n",
    "\n",
    "dic_ylabel = {\n",
    "    'cons': \"Consensus\", \n",
    "    \"yasa\": \"YASA\", \n",
    "    'stephansen': \"Stephansen 2018\", \n",
    "    \"perslev\": \"Perslev 2021\"}\n",
    "\n",
    "for dataset in ['dodh', 'dodo']:\n",
    "    pp = PdfPages(\"output/plots/%s_hypnograms.pdf\" % dataset)\n",
    "    \n",
    "    # Find subject order\n",
    "    order = (\n",
    "        df_scores.xs((dataset, \"yasa\"), level=[1, 2])\n",
    "                 .sort_values(\"accuracy\", ascending=False)\n",
    "                 .index.get_level_values(0).tolist()\n",
    "    )\n",
    "\n",
    "    for subj in tqdm(order):\n",
    "        df_subj = df[df['subj'] == subj].copy().replace(STR2NUM)\n",
    "        t_hyp = np.arange(df_subj.shape[0]) / 120\n",
    "        hypnos = df_subj[['cons', 'yasa', 'stephansen', 'perslev']].copy()\n",
    "        hypnos.replace({0: 0, 1: 2, 2: 3, 3: 4, 4: 1}, inplace=True)  # REM is now 1\n",
    "        hypnos_REM = hypnos.where(hypnos == 1)\n",
    "\n",
    "        fig, axes = plt.subplots(nrows=4, figsize=(10, 10), sharex=True, sharey=True)\n",
    "        plt.subplots_adjust(hspace=0.2)\n",
    "\n",
    "        for i, ax in enumerate(axes):\n",
    "            # Hypnogram (top axis)\n",
    "            ax.step(t_hyp, -1 * hypnos.iloc[:, i], lw=1.5, color='k')\n",
    "            ax.step(t_hyp, -1 * hypnos_REM.iloc[:, i], lw=1.5, color='tab:red')\n",
    "\n",
    "            # No artefacts or Unscored\n",
    "            ax.set_yticks([0, -1, -2, -3, -4])\n",
    "            ax.set_yticklabels(['W', 'R', 'N1', 'N2', 'N3'])\n",
    "            ax.set_ylim(-4.5, 0.5)\n",
    "\n",
    "            ax.set_xlim(0, t_hyp.max())\n",
    "            ax.xaxis.set_visible(False)\n",
    "            ax.spines['right'].set_visible(False)\n",
    "            ax.spines['top'].set_visible(False)\n",
    "            ax.set_ylabel(dic_ylabel[hypnos.iloc[:, i].name], fontweight=\"bold\")\n",
    "\n",
    "            # Annotate accuracy\n",
    "            if i > 0:\n",
    "                acc = 100 * skm.accuracy_score(hypnos.iloc[:, 0], hypnos.iloc[:, i])\n",
    "                ax.annotate(\n",
    "                    f\"Accuracy = {acc:.2f}%\", xy=(1, 0.1), xycoords=\"axes fraction\", \n",
    "                    ha=\"right\", color=\"tab:blue\", fontweight=\"bold\")\n",
    "\n",
    "\n",
    "        ax.xaxis.set_visible(True)\n",
    "        ax.set_xlabel(\"Time (hours)\")\n",
    "        \n",
    "        axes[0].set_title(f\"{subj}\", fontweight=\"bold\")\n",
    "        plt.tight_layout()\n",
    "        pp.savefig(dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "    pp.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
